{"cells":[{"cell_type":"markdown","metadata":{"id":"Sn-4AoG1jA9y"},"source":["Carga el conjunto de datos MNIST y divídelo en un conjunto de entrenamiento, un conjunto de validación y un conjunto de prueba (por ejemplo, divide en entrenamiento y prueba (20%), después divide los datos de entrenamiento tomando las primeras 1000 muestras para entrenamiento y el resto para validación)."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"PNv-TyBXjAB4"},"outputs":[],"source":["import numpy as np\n","from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.datasets import load_digits"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"fJFynnh2jVSO"},"outputs":[],"source":["mnist = load_digits()\n","X = mnist.data\n","y = mnist.target"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Fmpt6lz5FtQn"},"outputs":[{"data":{"text/plain":["(1797, 64)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["X.shape"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n","X_value = X_train[1000:]\n","y_value = y_train[1000:]\n","X_train = X_train[:1000]\n","y_train = y_train[:1000]"]},{"cell_type":"markdown","metadata":{"id":"ocBXgGc7k1ZF"},"source":["Entrena clasificadores individuales, que por lo menos alcancen 0.5 de desempeño en los datos de validación. Por ejemplo un clasificador DecisionTree, un clasificador SVM y un MLP."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"EWwEQAIUFtyu"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tasa de aciertos: 0.65\n"]}],"source":["from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","svm_clf = SVC(C=3, gamma=0.012)\n","\n","svm_clf.fit(X_train, y_train)\n","y_pred = svm_clf.predict(X_value)\n","\n","# Calcula la tasa de aciertos de las predicciones del clasificador\n","tasa_aciertos = accuracy_score(y_value, y_pred)\n","\n","print(f'Tasa de aciertos: {tasa_aciertos:.2f}')\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Tasa de aciertos: 0.6861111111111111\n"]}],"source":["tree_clf = DecisionTreeClassifier(random_state=2, max_depth=5)\n","tree_clf.fit(X_train, y_train)\n","\n","print(f'Tasa de aciertos: {tree_clf.score(X_test, y_test)}')"]},{"cell_type":"markdown","metadata":{"id":"fmqn3kCGn_oh"},"source":["Entrena un modelo de Bagging y un modelo de Boosting para cada tipo de clasificador y compara los resultados usando los datos de validación."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"txMhQRfHFun8"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.894\n","0.8924485125858124\n"]}],"source":["bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=5),\n","                            n_estimators=50,\n","                            max_samples=100,\n","                            max_features = 1.0,\n","                            bootstrap = True,\n","                            oob_score=True,\n","                            n_jobs=-1,\n","                            random_state=2)\n","bag_clf.fit(X_train, y_train)\n","print(bag_clf.oob_score_)\n","print(bag_clf.score(X_value, y_value))"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.227\n","0.22777777777777777\n"]}],"source":["bag_clf = BaggingClassifier(SVC(C=3, gamma=0.012),\n","                            n_estimators=50,\n","                            max_samples=100,\n","                            max_features = 1.0,\n","                            bootstrap = True,\n","                            oob_score=True,\n","                            n_jobs=-1,\n","                            random_state=2)\n","bag_clf.fit(X_train, y_train)\n","print(bag_clf.oob_score_)\n","print(bag_clf.score(X_test, y_test))"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\anaso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["SVC score:\n","0.6972222222222222\n","SVC Adaboost score:\n","0.7388888888888889\n"]}],"source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","svc = SVC(\n","    C=3, probability=True, gamma=.012\n",")\n","\n","ada_clf = AdaBoostClassifier( svc,\n","                              n_estimators=3,\n","                              learning_rate=0.9,\n","                              random_state=0\n","                             )\n","\n","ada_clf.fit(X_train, y_train)\n","\n","svc.fit(X_train, y_train)\n","\n","print(\"SVC score:\")\n","print(svc.score(X_test, y_test))\n","print(\"SVC Adaboost score:\")\n","print(ada_clf.score(X_test, y_test))"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\anaso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Decision Tree Adaboost:\n","0.7222222222222222\n"]}],"source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","ada_clf = AdaBoostClassifier( DecisionTreeClassifier(max_depth=5),\n","                              n_estimators=3,\n","                              learning_rate=0.9,\n","                              random_state=0\n","                             )\n","\n","ada_clf.fit(X_train, y_train)\n","\n","svc.fit(X_train, y_train)\n","\n","print(\"Decision Tree Adaboost:\")\n","print(ada_clf.score(X_test, y_test))"]},{"cell_type":"markdown","metadata":{"id":"maPj__VQo5zw"},"source":["Al ensamble con mejor resultado evalualo con los datos de prueba"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XdOWFTspFvV-"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyODzdUoixuvZjkVA7At5mdX","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
